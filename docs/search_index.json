[
["index.html", "Data Visualisation Module Welcome Prerequisite Acknowledgements Contact information for instructor", " Data Visualisation Module Welcome Welcome to the practical sessions of Visualisation module. This course is a collection of instructions and exercises designed to build: A foundation in exploratory data analysis in R. Ability to apply appropriate data transformation and create elegant and informative data visualisations that help you understand data and communicate findings. Working knowledge of other data visualization systems and libraries, including Tableau, D3, and libraries in Python. R is one of the fast growing programming languages and tool of choice for analysts and data scientists. In part, R owes its popularity to its open source distribution and large user community. In this course, we will primarily focus on R as a language of choice to put visualization theories into practice. Prerequisite This course is intended for those who have at least a basic programming experience in R. Acknowledgements This course material has been inspired and influenced by other course materials, articles and books: R Graphics Cookbook 2e. Winston Chang. O’Reilly. Contact information for instructor Ryo Sakai (r.sakai@imperial.ac.k) "],
["gettingStarted.html", "Chapter 1 Getting started 1.1 Installing R and IDE 1.2 Getting help 1.3 Installing packages 1.4 Rmarkdown introduction 1.5 R data structure review", " Chapter 1 Getting started 1.1 Installing R and IDE If you have not installed R on your computer: Go to https://cran.r-project.org/ Click Download R for Mac/Windows Download the appropriate file: Windows user - click Base and download the installer for the latest R version Mac user - select the file R-3.X.X.pkg that matches with your OS version Follow the instructions of the installer If you have not installed RStudio for desktop: Go to RStudio for desktop Select the appropirate installer for your computer Follow the instructions of the installer There are many useful features to RStudio. I recommend watching the IDE overview video on this page. There are also useful webinar recordings on RStudio website, and this video is very good (up to 30:20 for RStudio Desktop features)! 1.2 Getting help R comes with many predefined functions and packages come with thier own functions. You will be familiar with some functions that you use often, but there is no point trying to remember every functions. The below are some useful functions built in to look up details for specific functions. # help function provides details, or you can just put a question mark before the function help(sqrt) ?sqrt Other sources to look up: Google : add “with R” at the end of your query, or name of library Stack Overflow R-bloggers: news and tutorials for R users 1.3 Installing packages A package is a fundamental unit of shareable code. There are 3 main repositories of packages: CRAN, Bioconductor, and GitHub. # how to install packages from CRAN install.packages(&quot;packagename_1&quot;) install.packages(c(&quot;packagename_1&quot;, &quot;packagename_2&quot;)) # install pakcages from Bioconductor source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite() biocLite(&quot;packagename&quot;) # install packages from GitHub install.packages(&quot;devtooos&quot;) devtools::install_github(&quot;username/packagename&quot;) 1.4 Rmarkdown introduction 1.5 R data structure review "],
["introduction-to-ggplot2.html", "Chapter 2 Introduction to ggplot2 2.1 Overview 2.2 tidyverse package 2.3 ggplot2 package 2.4 Visual analytics - Intro 2.5 Facets 2.6 Geometric objects 2.7 A layered grammar of graphics 2.8 Statistical transformations 2.9 Position adjustments 2.10 Novel graphs", " Chapter 2 Introduction to ggplot2 “The simple graph has brought more information to the data analyst’s mind athan any other device.” — John Tukey 2.1 Overview R has several systems for data visualisation, and ggplot2 is arguably the most elegant and versatile visualisation package, which implements the grammar of graphics theory. 2.2 tidyverse package tidyverse is a collection of R packages designed for data science, which includes ggplot2 package for plotting and dplyr package for data wrangling. Install the latest tidyverse package and loading the package # Install if you have not install, or to update the pacakge install.packages(&quot;tidyverse&quot;) # Load the package library(tidyverse) # We will use this dataset for this section mpg ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl cla… ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;ch&gt; ## 1 audi a4 1.8 1999 4 auto… f 18 29 p com… ## 2 audi a4 1.8 1999 4 manu… f 21 29 p com… ## 3 audi a4 2 2008 4 manu… f 20 31 p com… ## 4 audi a4 2 2008 4 auto… f 21 30 p com… ## 5 audi a4 2.8 1999 6 auto… f 16 26 p com… ## 6 audi a4 2.8 1999 6 manu… f 18 26 p com… ## 7 audi a4 3.1 2008 6 auto… f 18 27 p com… ## 8 audi a4 q… 1.8 1999 4 manu… 4 18 26 p com… ## 9 audi a4 q… 1.8 1999 4 auto… 4 16 25 p com… ## 10 audi a4 q… 2 2008 4 manu… 4 20 28 p com… ## # ... with 224 more rows TASK: Look up a vignette for the tidyverse package. Find additional documentation on mpg dataset to learn more about the dataset. Answer Opening vignette for tidyverse: vignette(package =“tidyverse”) vignette(“manifesto”, package =“tidyverse”) Check the dataset: ?mpg 2.3 ggplot2 package Now that you have a better understanding of mpg dataset,let’s start with a simple question/hypothesis: Do casrs with big engines use more feul than cars with small engignes? You may already have a hunch to answer this question, but what do you think the relationship between engine size and fuel efficiency is like? It is a linear or non-linear function? TASK: Look up which variable is for car’s engine size in mpg dataset. Look up which variable is for car’s fuel efficiency in mpg dataset. Answer Opening vignette for tidyverse: displ variable is for car’s engine size in liters. hwy variable is for car’s fuel efficiency on the highway, in miles per gallon. 2.3.1 qplot() ggplot2 comes with a function called qplot(), which is quivalent to the base plot() function. It is a convenient wrapper for creating a number of different types plots using a consistent calling scheme, but since this is a data visualization course, we will stick with ggplot() as it allows you to choose visual channels to create more complex graphics. 2.3.2 ggplot() Let’s start creating a scatter plot with displ on the x-axis and hwy on the y-axis to explore the relationship between the engine size and the fuel efficiency. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) The graph above shows a negative relationship between engine size and fuel efficiency, suggeting that cars with bitter engines tend to use more fuel. To create a plot with ggplot2, you follow these steps: ggplot() creates a coordinate system that you can add layers of geom (geometric object) to. The first argument of ggplot() is the data table to use in the graph. Thus, ggplot(data = mpg) create an empty graph, just pointing to the data source for plotting. To actually plot something, you need to choose a visual channel, calledgeom in ggplot2 term. The function geom_point() adds a geom layer of points to your graph, resulting a scatterplot. There are many geom functions and each geom function takes a mapping argument, in which you define the data mapping. The mapping argument is always paired with aes(). In this example, x and y arguments of aes() specify which variables to mapt to the x and y axes. In summary, a template looks like this: ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) I find this ggplot2 cheat sheet from RStudio very helpful to have this print out laying around on my desk while doing exploratory data analysis. TASK: Run ggplot(data = mpg). What do you see? How many rows are in mpg? How many columns/variables? What does the drv variable describe? Make a scatterplot of hwy on x-axis and cyl on y-axis. Make a scatter plot of class vs drv. Why is the plot not very useful? (Wickham and Grolemund 2016) 2.4 Visual analytics - Intro Let’s have a closer look at the graph you generated above. It looks liek one group of points highlighted in red seem to fall out of the linear trend. These cars have relatively large engine size (displ) and higher fuel efficiency (hwy) than you might expect. TASK: Think about why this may be. Look up ?mpg to see what other variables you may consider to address your hypothesis If you look up ?mpg, you see a variable called class which indicates types of car. This class variable might be an interesting variable to explore further. To get a quick glimps of what values are included in this variable, run table(mpg$class). In this table, you can see that class is a categorical variable of 7 categories. Var1 Freq 2seater 5 compact 47 midsize 41 minivan 11 pickup 33 subcompact 35 suv 62 From the lecture, you have learned that colour is a good visual channel for categorical data, so let’s colour each dots based on the class. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color= class)) + geom_point() TASK: Run the following code. Why are the points not blue? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color =“blue”)) Which variables in mpg are categorical? Which variables are quantitative? (Hint: ?mpg to read the documentation for the data set) Try mapping a quantitative variable to color, size and shape. How do these aesthetics behave differently for categorical vs. quantitative variables? What happens if you map the same variable to multiple aesthetics? What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point) What happens if you map an aesthetic to something other than a variable name, like aes(color = displ &lt; 5)? (Wickham and Grolemund 2016) 2.5 Facets Faceting is a powerful and general technique where you partition your data and small multiple plots side by side. Comparing multiple views side by side is easier compared to changing a plot with a selected varialble at a time. ggplot2 comes with useful functions facet_wrap() and facet_grid(). To facet your plot bya single categorical variable, let’s try with facet_wrap(). The first argument you need to pass to this function is a formula. Run the example code below and see if you can see any patterns in the output. ggplot(data = mpg)+ geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) You can also partition into a matrix by passing two categorical variables. We will use facet_grid() and pass a formula also. Let’s create a matrix of drv (f = front-wheel drive, r = rear wheel drive, 4 = 4wd) and cyl (number of cylinders). ggplot(data = mpg)+ geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl) You notice in the matrix of small multiples, the labels for faceting are missing. You can adjust the labels by passing labeller argument in facet_grid() function, as shown below. It is a good practice to generate graphs and make them easier to understand and make them less error-prone. ggplot(data = mpg)+ geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl, labeller = label_both) TASK: What happens if you facet on a continuous varialbe? What does the following code make? What does . do in the facet_grid formula? ggplot(data = mpg)+ geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ ., labeller = label_both) ggplot(data = mpg)+ geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(. ~ cyl, labeller = label_both) When using facet_grid() you should usually put the categorical variable with more categories in the columns. Why? (Wickham and Grolemund 2016) 2.6 Geometric objects How are these following plots similar? These plots are different representations of the same dataset. In ggplot, we can choose different geom functions to apply basic statistical transformation and create plots. The below is the code used to generate the two graphs above. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy)) TASK: Review the geom functions and its mapping argument it takes in the ggplot2 cheat sheet. Creativity in designing a plot comes to play when you think of layering multiple geom functions. Run the code: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + geom_smooth(mapping = aes(x = displ, y = hwy)) The code below also produces the same graph. Why is it a better code than the above? ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() Think of what the output will look like, then run the following code to check your prediction. What does se argument do? What does show.legend argument do? ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE, show.legend = FALSE) See if you can reproduce the follwoing plots: Answer Last task: ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_smooth(aes(group = drv), se = FALSE) + geom_point() ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(se = FALSE) ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(aes(color = drv)) + geom_smooth(aes(linetype = drv), se = FALSE) ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(size = 4, colour = &quot;white&quot;) + geom_point(aes(colour = drv)) (Wickham and Grolemund 2016) 2.7 A layered grammar of graphics This section’s content is based on this article by Hadley Wickham. (Wickham 2010) We are going to try to reproduce the top part of Minard’s famous depiction of Napoleon’s march on Russia, as shown below. Image from:https://en.wikipedia.org/wiki/File:Minard.png The top part of the graph displays the number of troops druing the advance and retreat, while the bottom part represents the temperature change during the advance. For this tutorial, as we are focusing on the top part, two relevant datasets are cities and troops. Each city has a position (a latitude and longitude), and a name. Each troop observation has a position, a direction (advance or retreat), and number of survivors. Although this may not be obvious, there is an additional variable which separates the arms of the advance and retreat. To get started, first download the datasets in the supplementary files from this page, then save the unzipped file in the folder in your working directory. For the codes below, I have saved the data files in a directory called “data”. 2.7.1 Loading the data Let’s load the data. Details on how to load other types of file will be covered in another lecture. TASK: Examine the troops and cities data tables and consider how you might approach about reproducing the graph. Let’s start with drawing the troops marching paths. Using the lat and long, we will first draw lines. Notice that we are using the group argument to group draw 3 paths separately. # put the legend on the bottom ggplot(data = troops) + geom_path(mapping = aes(x = long, y = lat, group = group)) Now that we have the paths, we can draw draw each segments with varying size, and direction. We define additional arguments in aes(). # put the legend on the bottom ggplot(data = troops) + geom_path(mapping = aes(x = long, y = lat, size = survivors, colour = direction, group = group)) + theme(legend.position=&quot;bottom&quot;) Now that you have the essence of the graph, let’s add the labels. ggplot() + geom_path(data = troops, mapping = aes(x = long, y = lat, size = survivors, color = direction, group = group)) + geom_text(data = cities, mapping = aes(x = long, y = lat, label = city), size = 4) + theme(legend.position=&quot;bottom&quot;) To finish up the graph by adjusting the range of line thickness. ggplot() + geom_path(data = troops, mapping = aes(x = long, y = lat, size = survivors, color = direction, group = group), lineend = &quot;round&quot;, linejoin = &quot;mitre&quot;) + scale_size(range = c(0.5, 12), limits = c(4000, 350000), trans = &quot;identity&quot;, breaks = c(100000, 200000, 300000), labels = c(&quot;100k&quot;, &quot;200k&quot;, &quot;300k&quot;))+ scale_color_manual(values = c(&quot;#E5CBAA&quot;,&quot;black&quot;), labels = c(&quot;Advance&quot;, &quot;Retreat&quot;)) + xlab(NULL) + ylab(NULL) + geom_point(data = cities, mapping = aes(x = long, y = lat, label = city), size = 1, color = &quot;red&quot;)+ geom_text(data = cities, mapping = aes(x = long, y = lat, label = city), size = 3, color = &quot;red&quot;, hjust =-0.1) + theme_bw()+ theme(legend.position=&quot;bottom&quot;)+ guides(size = guide_legend(title = NULL), color = guide_legend(title =NULL)) The final plot is nowhere near plished as Minard’s map, but it captures the essence and demonstrates the flexibility of ggplot2. If you are interested in how to take the output a little further, Andrew Heiss wrote a tutorial here. 2.8 Statistical transformations ggplot() includes a number of statistical transformations that runs behind the scene. It is subtle, but it is important to understand the inner working of a seemingly simple bar chart shown below. Let’s look at the following 2 lines of codeand the generated bar chart. For this section we will use diamonds datasets, which comes with ggplot2 pacakge. To learn more about the datasets run ?diamonds. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut)) The bar chart above shows the number of diamonds data points per quality of cut. It shows that the datasets contains more diamonds with higher quality cuts than that of low quality cuts. Notice that you only defined the x-axis (cut) above and the count on the y-axis is derived without explicit instruction. Depending on the geom type you choose, a default statistical transformation (stat for short) is applied. To learn more about the stat arguement, inspect the function by running ?geom_bar(). The default value for stat is count, which means that geom_bar() uses stat_count() by defualt. In the geom_bar() documentation, if you scroll down, you will see a section called Computed variables, under which it lists count and prop and how they are computed. There are number of cases you may want to override this default statistical transformation: What You See Is What You Get (WYSIWYG) You may want to pre-calculate and supply the values exactly to create a bar charts. Use stat = &quot;identity&quot; to define values for x and y. # summary cut &lt;- c(&quot;Fair&quot;,&quot;Good&quot;, &quot;Very Good&quot;, &quot;Premium&quot;, &quot;Ideal&quot;) freq &lt;- c(1610, 4906, 12082, 13791, 21551) demo &lt;- data_frame(cut, freq) ggplot(data = demo) + geom_bar(mapping = aes(x = cut, y = freq), stat = &quot;identity&quot;) Using other computed variables You may wish to use other computed variables. In the case of geom_bar(), prop returns groupwise proportion. Note: group = &quot;demo&quot; is passed in the aes() to override its default grouping by each level of cut separately. Try running without group = &quot;demo&quot;, and see what you get. In other words, you can call the group whatever you like, e.g. group = &quot;x&quot;. Note: To access a computed variables, you surrounds the variable name with two periods, as shown as ..prop... ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., group = &quot;demo&quot;)) Using non-defualt statistical transformation You may choose to use other statistical transformations. (See the ggplot2 sheet for other stats) Let’s look at stat_summary(). Note: cut is a categorical variable. depth is a quantitative/continuous variable for the total depth percentage. ggplot(data = diamonds) + stat_summary( mapping = aes(x = cut, y = depth), fun.ymin = min, fun.ymax = max, fun.y = median) TASK: What is the default geom associated with stat_summary()? How can you rewrite the previous plot to use that geom function instead of the stat function? What does geom_col() do? How is it different to geom_bar()? (Hint: Read the documentation) What variables does stat_smooth() computer? What are parameters involved in controlling its behaviour? (Wickham and Grolemund 2016) 2.9 Position adjustments The position argument specifies how the graphs are drawn, while stat defines the statistical transformation. Let’s look at the following example: ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) By specifying “fill” aesthetics in the barchart, it creates a stacked barchart because the default position adjsutment for geom_bar is stack. (Check the documentation ?geom_bar). For geom_bar, you can use one of four options: stack : default option to create a stacked barcharts identity : un-stacked, draws each object exactly where it falls in the context of the graph. This option is not very helpful as bars overlap dodge : avoids overlapping bars by placing beside one another fill : works like stack but visualise the proportions across groups ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;dodge&quot;) ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;fill&quot;) 2.9.1 geom_jitter() Another type of position adjustment that is useful for a scatter plot to aviod overplotting is position = &quot;jitter&quot;, where small amount of random noise to each point is added to spread the overlapping points out. See the two graphs below with and without jitter. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), position = &quot;jitter&quot;, alpha = 0.5)+ ggtitle(&quot;with jitter&quot;) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), alpha = 0.5)+ ggtitle(&quot;without jitter&quot;) TASK: What parameters to geom_jitter() control the amount of displacement? Try reproducing the following plot. (Hint: look up coord_flip()) (Wickham and Grolemund 2016) 2.10 Novel graphs References "],
["data-transformation.html", "Chapter 3 Data transformation 3.1 Importing data 3.2 Data transformation 3.3 Tidy data", " Chapter 3 Data transformation “Up to 80% of data analysis is spent on the process of cleaning and preparing data.” — cf. Wickham, 2014 and Dasu &amp; Johnson, 2003 In this chapter, we go over things you need to do before you visualise your data. In practice, it is rare that you are handed off clean data which are perfectly structured and ready for you to visualise the data. More often than not, you find yourself spending more time collecting, cleaning and wrangling data in data visualisation projects. Thus, getting efficient at data preparation is an important skill set for data visualisation. 3.1 Importing data For importing tabular data, we will use readr packcage, which is included in tidyverse for a couple of reasons. 1) It is much faster than base R function such as read.csv(). 2) It loads as tibbles instead of R’s traditional data.frame. Tibbles are data frames and for our purpose, there is no critical difference, and you can consider tibbles as “updated” version of data.frame which is more user friendly. # Load tidyverse package library(tidyverse) 3.1.1 Delimited text data file Function Description read_csv() comma separated (csv) files read_tsv() tab seaparated files read_delim() general delimited files read_fwf() fixed width files read_table() tabular files where columns are separated by white-space car_data &lt;- read_csv(file = &quot;data/mtcars.csv&quot;) ## Parsed with column specification: ## cols( ## mpg = col_double(), ## cyl = col_integer(), ## disp = col_double(), ## hp = col_integer(), ## drat = col_double(), ## wt = col_double(), ## qsec = col_double(), ## vs = col_integer(), ## am = col_integer(), ## gear = col_integer(), ## carb = col_integer() ## ) Note that readr function rpints the column specification. This output is useful to check that columns have been read in as you would expect. If they have not, you can copy-paste and edit into a new call. car_cata &lt;- read_csv(file = &quot;data/mtcars.csv&quot;, col_types = cols( mpg = col_double(), cyl = col_integer(), disp = col_double(), hp = col_integer(), drat = col_double(), vs = col_integer(), wt = col_double(), qsec = col_double(), am = col_integer(), gear = col_integer(), carb = col_integer() ) ) Besides col_integer() and col_double(), there are also col_logical() and col_character(). Read the documentation for more details. 3.1.2 Data from an excel file To load .xls or .xlsx files, use read_excel() function in the readxl package. With this function, you can specify the sheet of an Excel spreadsheet. Read the documentaiton for more details. # install the package for the first time install.packages(&quot;readxl&quot;) library(readxl) # Loading the first sheet of an Excel file data &lt;- read_excel(&quot;sample.xlsx&quot;, 1) 3.1.3 Data from SPSS/SAS/Stata files The haven packages include functions for reading data from SPSS/SAS/Stata files. Function Description read_sav() reading SPSS files read_sas() reading SAS files read_dta() reading Stata files 3.2 Data transformation For data transformation, we will use the dplyr package, which is also a part of tidyverse. The dplyr is a powerful R package to manipulate, clean and summarise unstructure data, which is user friendly and often much faster than base R functions. 3.2.1 Core verbs in dplyr If you are familiar with SQL, there are some similarities in the name of functions defined in dplyr. The table below contains core functions in dplyr, which you will be very familiar with. Also the cheatsheet from RStudio is very handy. Function Description Equivalent SQL select() selecting columns SELECT filter() filtering rows / subsetting WHERE group_by() grouping data GROUP BY summarise() summarising / aggregating data - arrange() sorting data ORDER BY join() joining data tables JOIN mutate() creating new columns COLUMN ALIAS All functions work similarly: * The first argument is a data frame * Subsequent arguments describe what to do * Output is a new data frame 3.2.2 Chaining function with the pipe operator The key player in dplyr is %&gt;% (called the pipe operator). It is important to understand the pipe oerator because it allows you to pass the result to another function and another… in a way that is easy to read. You will be using this pipe operator quite often, so it is good to memorise its keyboard shortcuts in RStudio. Command + Shift + M (for Mac). CTRL + Shift + M (for Windows) # without pipe to subset &quot;suv&quot; cars filter(mpg, class == &quot;suv&quot;) # equivalent form with pipe mpg %&gt;% filter(class == &quot;suv&quot;) 3.2.3 Tutorial Chapter 5 : Data transformation(Wickham and Grolemund 2016) from R for Data Science book is excellent for learning dplyr. Go to the ebook and read through Chapter 5 and complete following exercises: 5.2.4 5.3.1 5.4.1 5.5.2 5.6.7 5.7.1 3.2.4 Dates and times Chapter 16 in (Wickham and Grolemund 2016)(https://r4ds.had.co.nz/dates-and-times.html) covers how to handle dates and times using the lubridate package. Read through Chapter 16 and complete following exercises: 16.2.4 16.3.4 16.4.5 3.3 Tidy data In data analysis (espcially with tidyverse) in R, tidy data is a particular data structure recommended. There are 3 rules which make a dataset tidy: Each variable must have its own column Each observation must have its own row Each value must have its own cell This data structure may not be the easiest table to read, or most efficient table structure for storage, however it works well with tools provided by the packages in the tidyverse, beyond data visualisation. It will require some upfront work, but that work pays off in the long run. Which table shown below is tidy data? Table 1 country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 Table 2 country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 Table 3 country year rate Afghanistan 1999 745/19987071 Afghanistan 2000 2666/20595360 Brazil 1999 37737/172006362 Brazil 2000 80488/174504898 China 1999 212258/1272915272 China 2000 213766/1280428583 Answer: only Table 1 is tidy. Here is an example of data visualisation using Table 1, which works nicely and concisely. ggplot(table1, aes(year, cases)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) However, in reality, the data is not always tidy. We will cover 4 key function to tidy the data. 3.3.1 gather() Gathering multiple columns into one is useful when each row represents more than one observations. Suppose the table you have is as shown below, and you want to restructure to tidy so that it becomes like Table 1. country 1999 2000 Afghanistan 745 2666 Brazil 37737 80488 China 212258 213766 To achieve this, you use gather() function as follows: (tidy_4a &lt;- table4a %&gt;% gather(key = &quot;year&quot;, value = &quot;cases&quot;, `1999`, `2000`)) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 gather 3.3.2 spread() Spreading is the oposite of gathering. The below shows reversing the previous gathering. This is not very useful as the output is not tidy anymore. tidy_4a %&gt;% spread(key = year, value = cases) ## # A tibble: 3 x 3 ## country `1999` `2000` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 Spreading is useful when one observation is scattered across multiple rows. Let’s revisit Table 2. If you see type column, it contains 2 variables (cases and population) which should be in separate columns. country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 To trans form the Table 2, apply spread() function as shown below: table2 %&gt;% spread(key = type, value = count) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 spread 3.3.3 separate() separate() function is for splitting one column into mutiple columns to satisfy the third tidy data rule (Each value must have its own cell). Let’s revisit Table 3. The rate column actually consists of case and population values. country year rate Afghanistan 1999 745/19987071 Afghanistan 2000 2666/20595360 Brazil 1999 37737/172006362 Brazil 2000 80488/174504898 China 1999 212258/1272915272 China 2000 213766/1280428583 To split the rate column, pass the names of the columns to separate into, and the separator (in our case “/”). Another useful argument is convert = TRUE, to conver the column types to appropriate column types. Without this argument, the output columns will be character columns. table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep=&quot;/&quot;, convert = TRUE) ## # A tibble: 6 x 4 ## country year cases population ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 If you pass numeric to sep, it interprets as positions to split at. For example, you can splet the year into century and year. table3 %&gt;% separate(year, into = c(&quot;century&quot;, &quot;year&quot;), sep = 2) ## # A tibble: 6 x 4 ## country century year rate ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745/19987071 ## 2 Afghanistan 20 00 2666/20595360 ## 3 Brazil 19 99 37737/172006362 ## 4 Brazil 20 00 80488/174504898 ## 5 China 19 99 212258/1272915272 ## 6 China 20 00 213766/1280428583 3.3.4 unite() unite() is the oposite of separate(). Table 5 country century year rate Afghanistan 19 99 745/19987071 Afghanistan 20 00 2666/20595360 Brazil 19 99 37737/172006362 Brazil 20 00 80488/174504898 China 19 99 212258/1272915272 China 20 00 213766/1280428583 table5 %&gt;% unite(new, century, year, sep = &quot;&quot;) ## # A tibble: 6 x 3 ## country new rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 3.3.5 Exercise Let’s apply what you have learned in this chapter to this tidyr::who dataset. This dataset consists of TB cases broken down by year, country, age, gender, and diagnosis method. Take a closer look at the data by running tidyr::who %&gt;% View() and also checking its documentation ?tidyr::who. country iso2 iso3 year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544 new_sp_m4554 new_sp_m5564 new_sp_m65 new_sp_f014 new_sp_f1524 new_sp_f2534 new_sp_f3544 new_sp_f4554 new_sp_f5564 new_sp_f65 new_sn_m014 new_sn_m1524 new_sn_m2534 new_sn_m3544 new_sn_m4554 new_sn_m5564 new_sn_m65 new_sn_f014 new_sn_f1524 new_sn_f2534 new_sn_f3544 new_sn_f4554 new_sn_f5564 new_sn_f65 new_ep_m014 new_ep_m1524 new_ep_m2534 new_ep_m3544 new_ep_m4554 new_ep_m5564 new_ep_m65 new_ep_f014 new_ep_f1524 new_ep_f2534 new_ep_f3544 new_ep_f4554 new_ep_f5564 new_ep_f65 newrel_m014 newrel_m1524 newrel_m2534 newrel_m3544 newrel_m4554 newrel_m5564 newrel_m65 newrel_f014 newrel_f1524 newrel_f2534 newrel_f3544 newrel_f4554 newrel_f5564 newrel_f65 Afghanistan AF AFG 1980 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1981 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1982 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1983 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1984 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1985 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1986 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1987 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1988 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1989 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1990 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1991 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1992 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1993 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1994 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1995 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1996 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1997 0 10 6 3 5 2 0 5 38 36 14 8 0 1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1998 30 129 128 90 89 64 41 45 350 419 194 118 61 20 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan AF AFG 1999 8 55 55 47 34 21 8 25 139 160 110 50 25 8 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Some issues with the structure: * redundant columns: country, iso2, iso3 specify the country. * odd variable names: new_sp_m014:newrel_f65 columns show counts of new TB cases recorded by group. Column names encode three variables that describe the group. * many missing values (NA) Let’s gather new_sp_m014:newrel_f65 columns and remove missing values (who1 &lt;- who %&gt;% gather(key = &quot;key&quot;, value = &quot;cases&quot;, new_sp_m014:newrel_f65, na.rm = TRUE)) ## # A tibble: 76,046 x 6 ## country iso2 iso3 year key cases ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan AF AFG 1997 new_sp_m014 0 ## 2 Afghanistan AF AFG 1998 new_sp_m014 30 ## 3 Afghanistan AF AFG 1999 new_sp_m014 8 ## 4 Afghanistan AF AFG 2000 new_sp_m014 52 ## 5 Afghanistan AF AFG 2001 new_sp_m014 129 ## 6 Afghanistan AF AFG 2002 new_sp_m014 90 ## 7 Afghanistan AF AFG 2003 new_sp_m014 127 ## 8 Afghanistan AF AFG 2004 new_sp_m014 139 ## 9 Afghanistan AF AFG 2005 new_sp_m014 151 ## 10 Afghanistan AF AFG 2006 new_sp_m014 193 ## # ... with 76,036 more rows Next, let’s clean up the key column, e.g. new_sp_m014. You can get better understanding of what this column encodes in the documentation: new endoces new cases of TB next two-three letters describe the type of TB: rel stands for cases of relapse ep stands for cases of extraplumonary TB sn stands for cases of pulmonary TB that could not be diagnosed by a pulmonary smear (smear negative) sp stands for smear positive m stands for males and f stands for female the remaining number indicates the age group. There are 7 age groups. For example 014 encodes 0-14 years old age group. Also you may have notices an inconsistency in naming of the key. With or wihtout an underscore line: new_rel and newrel. You can use strings:str_replace() to replace newrel with now_rel to make these value naming consistent. (who2 &lt;- who1 %&gt;% mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;))) ## # A tibble: 76,046 x 6 ## country iso2 iso3 year key cases ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan AF AFG 1997 new_sp_m014 0 ## 2 Afghanistan AF AFG 1998 new_sp_m014 30 ## 3 Afghanistan AF AFG 1999 new_sp_m014 8 ## 4 Afghanistan AF AFG 2000 new_sp_m014 52 ## 5 Afghanistan AF AFG 2001 new_sp_m014 129 ## 6 Afghanistan AF AFG 2002 new_sp_m014 90 ## 7 Afghanistan AF AFG 2003 new_sp_m014 127 ## 8 Afghanistan AF AFG 2004 new_sp_m014 139 ## 9 Afghanistan AF AFG 2005 new_sp_m014 151 ## 10 Afghanistan AF AFG 2006 new_sp_m014 193 ## # ... with 76,036 more rows Now use separate() to split key into 3 columns. (who3 &lt;- who2 %&gt;% separate(key, into = c(&quot;new&quot;, &quot;type&quot;, &quot;sex-age&quot;), sep =&quot;_&quot;)) ## # A tibble: 76,046 x 8 ## country iso2 iso3 year new type `sex-age` cases ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan AF AFG 1997 new sp m014 0 ## 2 Afghanistan AF AFG 1998 new sp m014 30 ## 3 Afghanistan AF AFG 1999 new sp m014 8 ## 4 Afghanistan AF AFG 2000 new sp m014 52 ## 5 Afghanistan AF AFG 2001 new sp m014 129 ## 6 Afghanistan AF AFG 2002 new sp m014 90 ## 7 Afghanistan AF AFG 2003 new sp m014 127 ## 8 Afghanistan AF AFG 2004 new sp m014 139 ## 9 Afghanistan AF AFG 2005 new sp m014 151 ## 10 Afghanistan AF AFG 2006 new sp m014 193 ## # ... with 76,036 more rows Let’s separate sex-age columns (who4 &lt;- who3 %&gt;% separate(`sex-age`, into = c(&quot;sex&quot;, &quot;age&quot;), sep = 1)) ## # A tibble: 76,046 x 9 ## country iso2 iso3 year new type sex age cases ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan AF AFG 1997 new sp m 014 0 ## 2 Afghanistan AF AFG 1998 new sp m 014 30 ## 3 Afghanistan AF AFG 1999 new sp m 014 8 ## 4 Afghanistan AF AFG 2000 new sp m 014 52 ## 5 Afghanistan AF AFG 2001 new sp m 014 129 ## 6 Afghanistan AF AFG 2002 new sp m 014 90 ## 7 Afghanistan AF AFG 2003 new sp m 014 127 ## 8 Afghanistan AF AFG 2004 new sp m 014 139 ## 9 Afghanistan AF AFG 2005 new sp m 014 151 ## 10 Afghanistan AF AFG 2006 new sp m 014 193 ## # ... with 76,036 more rows We can drop redundant or unnecessary columns, using dplyr::select(). who5 &lt;- who4 %&gt;% select(-new, -iso2, -iso3) The process above showed step by step, but in reality, you can build up a comple piped operations as shown below: who %&gt;% gather(key, value, new_sp_m014:newrel_f65, na.rm = TRUE) %&gt;% mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;)) %&gt;% separate(key, c(&quot;new&quot;, &quot;var&quot;, &quot;sexage&quot;)) %&gt;% select(-new, -iso2, -iso3) %&gt;% separate(sexage, c(&quot;sex&quot;, &quot;age&quot;), sep = 1) References "],
["exploratory-data-analysis.html", "Chapter 4 Exploratory data analysis 4.1 Case study: Movie data 4.2 Case study: Skiers 4.3 Graphs in 25 ways", " Chapter 4 Exploratory data analysis 4.1 Case study: Movie data 4.2 Case study: Skiers 4.3 Graphs in 25 ways In this blog post, Nathan Yau argues importance of asking questions, starting from basic visualizations and focusing your queries. TASK: Read the blog post Examine 25 data sketches Nathan created. Pick one visualization you like and explain: why you like the visualisation what question the visualisation addresses what you would do to improve the visualisation Bonus: Implement the visualisation in R. “Life Expectancy Data.csv” was downloaded from here. "],
["presentation.html", "Chapter 5 Presentation 5.1 Choosing colours 5.2 Annotations 5.3 Axes 5.4 Legend 5.5 Using themes 5.6 Export 5.7 Animation", " Chapter 5 Presentation 5.1 Choosing colours 5.2 Annotations 5.3 Axes 5.4 Legend 5.5 Using themes 5.6 Export 5.6.1 PDF, SVG, WMF vector files 5.6.2 Output for Powerpoint https://blog.revolutionanalytics.com/2017/10/office-charts.html rvg packcage 5.7 Animation 5.7.1 Editing a vector Output file "],
["visualisation-techniques.html", "Chapter 6 Visualisation techniques 6.1 Web-based visualisation in R 6.2 Network visualisation 6.3 Other techniques", " Chapter 6 Visualisation techniques 6.1 Web-based visualisation in R 6.1.1 plotly 6.1.2 crosstalk 6.2 Network visualisation 6.3 Other techniques 6.3.1 GGally: Extension to ggplot2 6.3.2 Upset diagram "],
["beyond.html", "Chapter 7 Beyond 7.1 Tableau tutorial 7.2 python tutorial 7.3 D3 tutorial 7.4 Useful blog posts", " Chapter 7 Beyond 7.1 Tableau tutorial 7.2 python tutorial Python tutoral given as aprt of Visual Analytics lab at JKU Linz: https://github.com/JKU-ICG/python-tutorial-VA2018?organization=JKU-ICG&amp;organization=JKU-ICG 7.3 D3 tutorial Excellent video tutorials by Curran Kelleher: https://curran.github.io/dataviz-course-2018/ 7.3.1 HTML widget 7.4 Useful blog posts R for Data Science: https://r4ds.had.co.nz/ R basics, workspace and working directory, RStudio projects: http://stat545.com/block002_hello-r-workspace-wd-project.html http://r-statistics.co/Complete-Ggplot2-Tutorial-Part1-With-R-Code.html "],
["final-project.html", "Chapter 8 Final project", " Chapter 8 Final project "],
["references.html", "References", " References "]
]
